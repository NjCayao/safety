"""
Test Mejorado del Sistema de Detecci√≥n de Distracciones
Con diagn√≥stico de problemas comunes
"""

import cv2
import sys
import os
import dlib
import time

# Agregar el directorio ra√≠z al path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.distraction import IntegratedDistractionSystem

def test_camera():
    """Prueba la c√°mara antes de iniciar el sistema"""
    print("\nüé• Probando c√°mara...")
    
    # Probar diferentes √≠ndices de c√°mara
    for index in [0, 1, 2]:
        cap = cv2.VideoCapture(index)
        if cap.isOpened():
            ret, frame = cap.read()
            if ret and frame is not None:
                h, w = frame.shape[:2]
                print(f"‚úÖ C√°mara {index} funciona: {w}x{h}")
                cap.release()
                return index
            cap.release()
    
    print("‚ùå No se encontr√≥ ninguna c√°mara funcional")
    return None

def main():
    print("\n=== TEST SISTEMA DE DETECCI√ìN DE DISTRACCIONES ===")
    print("Versi√≥n mejorada con diagn√≥stico")
    
    # 1. Verificar c√°mara primero
    camera_index = test_camera()
    if camera_index is None:
        print("\n‚ùå No se puede continuar sin c√°mara")
        print("Posibles soluciones:")
        print("  ‚Ä¢ Verifica que tu c√°mara est√© conectada")
        print("  ‚Ä¢ Cierra otras aplicaciones que usen la c√°mara")
        print("  ‚Ä¢ Verifica los permisos de la c√°mara")
        return
    
    # 2. Verificar modelo de landmarks
    print("\nüìÅ Verificando modelo de landmarks...")
    model_path = "assets/models/shape_predictor_68_face_landmarks.dat"
    if not os.path.exists(model_path):
        print(f"‚ùå Error: No se encuentra el modelo en {model_path}")
        print("Desc√°rgalo de: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2")
        return
    else:
        print("‚úÖ Modelo encontrado")
    
    # 3. Inicializar detectores
    print("\nüîß Inicializando detectores...")
    try:
        face_detector = dlib.get_frontal_face_detector()
        landmark_predictor = dlib.shape_predictor(model_path)
        print("‚úÖ Detectores inicializados")
    except Exception as e:
        print(f"‚ùå Error al inicializar detectores: {e}")
        return
    
    # 4. Crear sistema de distracciones
    print("\nüöÄ Inicializando sistema de distracciones...")
    try:
        distraction_system = IntegratedDistractionSystem(
            operators_dir="operators",
            dashboard_position='right'
        )
        print("‚úÖ Sistema inicializado")
    except Exception as e:
        print(f"‚ùå Error al inicializar sistema: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 5. Configurar operador de prueba
    test_operator = {
        'id': 'test_operator',
        'name': 'Operador de Prueba'
    }
    
    # Buscar operador real si existe
    if os.path.exists("operators"):
        operators = [d for d in os.listdir("operators") if os.path.isdir(os.path.join("operators", d))]
        if operators:
            print(f"\nüìã Operadores disponibles: {operators}")
            # Usar el primer operador encontrado
            test_operator['id'] = operators[0]
            operator_path = os.path.join("operators", test_operator['id'])
            info_file = os.path.join(operator_path, "info.txt")
            if os.path.exists(info_file):
                with open(info_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    if len(lines) > 1:
                        test_operator['name'] = lines[1].strip()
    
    distraction_system.set_operator(test_operator)
    
    status = distraction_system.get_current_status()
    print(f"\nüë§ Operador: {test_operator['name']} (ID: {test_operator['id']})")
    print(f"üìä Calibraci√≥n: {'PERSONALIZADA' if status['is_calibrated'] else 'POR DEFECTO'}")
    
    # 6. Configurar c√°mara con par√°metros optimizados
    print(f"\nüì∑ Abriendo c√°mara {camera_index}...")
    cap = cv2.VideoCapture(camera_index)
    
    # Configurar resoluci√≥n
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    # Verificar que la c√°mara funciona
    ret, test_frame = cap.read()
    if not ret or test_frame is None:
        print("‚ùå Error: La c√°mara no est√° capturando frames")
        cap.release()
        return
    
    print("‚úÖ C√°mara funcionando correctamente")
    print(f"   Resoluci√≥n: {test_frame.shape[1]}x{test_frame.shape[0]}")
    
    print("\n" + "="*50)
    print("CONTROLES:")
    print("  ‚Ä¢ q: Salir")
    print("  ‚Ä¢ d: Cambiar posici√≥n del dashboard")
    print("  ‚Ä¢ h: Ocultar/mostrar dashboard")
    print("  ‚Ä¢ r: Reiniciar contador de distracciones")
    print("  ‚Ä¢ f: Forzar reporte (testing)")
    print("  ‚Ä¢ ESPACIO: Pausar/reanudar")
    print("="*50 + "\n")
    
    dashboard_visible = True
    frame_count = 0
    fps_time = time.time()
    fps = 0
    paused = False
    last_frame = None
    
    print("üéØ Sistema listo. Mueve tu cabeza hacia los lados para probar.\n")
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret or frame is None:
                print("\n‚ùå Error al capturar frame")
                break
            
            # Voltear horizontalmente para efecto espejo
            frame = cv2.flip(frame, 1)
            last_frame = frame.copy()
        else:
            if last_frame is not None:
                frame = last_frame.copy()
            else:
                continue
        
        # Calcular FPS
        if frame_count % 30 == 0:
            current_time = time.time()
            if current_time - fps_time > 0:
                fps = 30 / (current_time - fps_time)
                fps_time = current_time
        
        # Detectar rostros
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_detector(gray, 0)
        
        landmarks = None
        if faces:
            # Dibujar rect√°ngulo del rostro
            face = faces[0]
            x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # Obtener landmarks
            landmarks = landmark_predictor(gray, face)
            
            # Dibujar algunos puntos clave para verificar
            for i in [30, 8, 36, 45]:  # Nariz, ment√≥n, ojos
                x = landmarks.part(i).x
                y = landmarks.part(i).y
                cv2.circle(frame, (x, y), 3, (0, 255, 255), -1)
        
        # Procesar con el sistema de distracciones
        result = distraction_system.analyze_frame(frame, landmarks)
        
        # Agregar informaci√≥n de debug en la imagen
        debug_frame = result['frame']
        cv2.putText(debug_frame, f"FPS: {fps:.1f}", (10, 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        if paused:
            cv2.putText(debug_frame, "PAUSADO", (10, 50), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # Mostrar estado en consola
        if frame_count % 30 == 0 and not paused:
            detector_status = result.get('detector_status', {})
            
            if detector_status:
                direction = detector_status.get('direction', 'CENTRO')
                alert_level = detector_status.get('current_alert_level', 0)
                distraction_time = detector_status.get('distraction_time', 0)
                
                if result.get('is_distracted', False):
                    level_str = f"Nivel {alert_level}" if alert_level > 0 else "Iniciando"
                    print(f"\rüü° DISTRACCI√ìN ({direction}) | "
                          f"{level_str} | "
                          f"Tiempo: {distraction_time:.1f}s | "
                          f"Total: {result['total_distractions']}/{result['max_distractions']} | "
                          f"FPS: {fps:.1f}    ", end='', flush=True)
                else:
                    print(f"\r‚úÖ Atento (CENTRO) | "
                          f"Distracciones: {result['total_distractions']}/{result['max_distractions']} | "
                          f"FPS: {fps:.1f}    ", end='', flush=True)
            else:
                print(f"\r‚è∏Ô∏è  Sin detecci√≥n de rostro | FPS: {fps:.1f}                    ", end='', flush=True)
        
        # Alertas especiales
        if result.get('multiple_distractions', False):
            if frame_count % 15 == 0:
                print(f"\n‚ö†Ô∏è  ALERTA: {result['total_distractions']} distracciones en {result['window_minutes']} minutos!")
        
        frame_count += 1
        
        # Mostrar frame
        cv2.imshow('Test Detecci√≥n de Distracciones', debug_frame)
        
        # Procesar teclas
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('q'):
            break
        elif key == ord('d'):
            new_pos = 'left' if distraction_system.dashboard.position == 'right' else 'right'
            distraction_system.set_dashboard_position(new_pos)
            print(f"\nüìä Dashboard movido a: {new_pos}")
        elif key == ord('h'):
            dashboard_visible = not dashboard_visible
            distraction_system.enable_dashboard(dashboard_visible)
            print(f"\nüìä Dashboard: {'visible' if dashboard_visible else 'oculto'}")
        elif key == ord('r'):
            distraction_system.reset_distraction_counter()
            print("\nüîÑ Contador reiniciado")
        elif key == ord('f'):
            if distraction_system.force_distraction_report(debug_frame):
                print("\nüì® Reporte generado en 'reports/distraction/'")
        elif key == ord(' '):
            paused = not paused
            print(f"\n‚è∏Ô∏è  {'PAUSADO' if paused else 'REANUDADO'}")
    
    # Resumen final
    print("\n\n" + "="*50)
    print("RESUMEN DE LA SESI√ìN")
    print("="*50)
    
    status = distraction_system.get_current_status()
    stats = status['session_stats']
    
    print(f"Total frames procesados: {frame_count}")
    print(f"Distracciones detectadas: {stats['total_distractions']}")
    print(f"Reportes generados: {stats['reports_generated']}")
    
    cap.release()
    cv2.destroyAllWindows()
    print("\n‚úÖ Test completado!")

if __name__ == "__main__":
    main()